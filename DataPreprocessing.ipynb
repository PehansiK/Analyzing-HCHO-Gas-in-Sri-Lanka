{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXl3LByIkH5E4l79gNeryo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkTkxhK6gw2m",
        "outputId": "4db0c76f-2756-4830-fcfa-ce8bb4bca70c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=1eb82a5ac61838046a8fb5e2fa9b66fccce3051d2d1e5b9739edf9a76d29e79d\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pyspark.sql  as pyspark_sql\n",
        "import pyspark.sql.types as pyspark_types\n",
        "import pyspark.sql.functions  as F\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "metadata": {
        "id": "v1VcLMghg8kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = pyspark_sql.SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "-THYHmYkhddh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load 3 datasets\n",
        "data1 = spark.read.csv(\"Dataset/col_mat_nuw_output.csv\", header=False, inferSchema=True)\n",
        "data2 = spark.read.csv(\"Dataset/kan_output.csv\", header=False, inferSchema=True)\n",
        "data3 = spark.read.csv(\"Dataset/mon_kur_jaf_output.csv\", header=False, inferSchema=True)"
      ],
      "metadata": {
        "id": "AYnytSmzhfqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.show(5)\n",
        "data2.show(5)\n",
        "data3.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0kuuAC6ioOy",
        "outputId": "1c0059d1-8ccc-4acf-c435-43880e4936f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+----------+----------+\n",
            "|                 _c0|           _c1|       _c2|       _c3|\n",
            "+--------------------+--------------+----------+----------+\n",
            "|1.969834395781014...|Colombo Proper|2019-01-01|2019-01-02|\n",
            "|2.625522171968594...|Colombo Proper|2019-01-02|2019-01-03|\n",
            "|9.852118897938794E-5|Colombo Proper|2019-01-03|2019-01-04|\n",
            "|2.099320518114242E-4|Colombo Proper|2019-01-04|2019-01-05|\n",
            "|1.785337298892930...|Colombo Proper|2019-01-05|2019-01-06|\n",
            "+--------------------+--------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+------------+----------+----------+\n",
            "|                 _c0|         _c1|       _c2|       _c3|\n",
            "+--------------------+------------+----------+----------+\n",
            "|1.760713459877335...|Kandy Proper|2019-01-01|2019-01-02|\n",
            "|9.220391253917748E-5|Kandy Proper|2019-01-02|2019-01-03|\n",
            "|                NULL|Kandy Proper|2019-01-03|2019-01-04|\n",
            "|1.908681983853839...|Kandy Proper|2019-01-04|2019-01-05|\n",
            "|1.219517840206744...|Kandy Proper|2019-01-05|2019-01-06|\n",
            "+--------------------+------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+------------------+----------+----------+\n",
            "|                 _c0|               _c1|       _c2|       _c3|\n",
            "+--------------------+------------------+----------+----------+\n",
            "|                NULL|Bibile, Monaragala|2019-01-01|2019-01-02|\n",
            "|1.919914652467399E-5|Bibile, Monaragala|2019-01-02|2019-01-03|\n",
            "|2.811447935930283...|Bibile, Monaragala|2019-01-03|2019-01-04|\n",
            "|3.747998184385943E-5|Bibile, Monaragala|2019-01-04|2019-01-05|\n",
            "|-1.79826087934531...|Bibile, Monaragala|2019-01-05|2019-01-06|\n",
            "+--------------------+------------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Column Names of data1\n",
        "data1 = data1.toDF(\"_c1\", \"_c2\", \"_c3\", \"_c4\").withColumnRenamed(\"_c1\", \"HCHO reading\").withColumnRenamed(\"_c2\", \"Location\").withColumnRenamed(\"_c3\", \"Current Date\").withColumnRenamed(\"_c4\", \"Next Date\")\n",
        "\n",
        "# Show DataFrame with renamed columns\n",
        "data1.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FPhNGGgnS6d",
        "outputId": "fa5ed351-ef51-47c4-ae15-e2cc7c971640"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+------------+----------+\n",
            "|        HCHO reading|      Location|Current Date| Next Date|\n",
            "+--------------------+--------------+------------+----------+\n",
            "|1.969834395781014...|Colombo Proper|  2019-01-01|2019-01-02|\n",
            "|2.625522171968594...|Colombo Proper|  2019-01-02|2019-01-03|\n",
            "|9.852118897938794E-5|Colombo Proper|  2019-01-03|2019-01-04|\n",
            "|2.099320518114242E-4|Colombo Proper|  2019-01-04|2019-01-05|\n",
            "|1.785337298892930...|Colombo Proper|  2019-01-05|2019-01-06|\n",
            "+--------------------+--------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Column Names of data2\n",
        "data2 = data2.toDF(\"_c1\", \"_c2\", \"_c3\", \"_c4\").withColumnRenamed(\"_c1\", \"HCHO reading\").withColumnRenamed(\"_c2\", \"Location\").withColumnRenamed(\"_c3\", \"Current Date\").withColumnRenamed(\"_c4\", \"Next Date\")\n",
        "\n",
        "# Show DataFrame with renamed columns\n",
        "data2.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkSbpIHsnnAy",
        "outputId": "b08506a4-e91c-46eb-ad8d-2553e1628536"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+------------+----------+\n",
            "|        HCHO reading|    Location|Current Date| Next Date|\n",
            "+--------------------+------------+------------+----------+\n",
            "|1.760713459877335...|Kandy Proper|  2019-01-01|2019-01-02|\n",
            "|9.220391253917748E-5|Kandy Proper|  2019-01-02|2019-01-03|\n",
            "|                NULL|Kandy Proper|  2019-01-03|2019-01-04|\n",
            "|1.908681983853839...|Kandy Proper|  2019-01-04|2019-01-05|\n",
            "|1.219517840206744...|Kandy Proper|  2019-01-05|2019-01-06|\n",
            "+--------------------+------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Column Names of data3\n",
        "data3 = data3.toDF(\"_c1\", \"_c2\", \"_c3\", \"_c4\").withColumnRenamed(\"_c1\", \"HCHO reading\").withColumnRenamed(\"_c2\", \"Location\").withColumnRenamed(\"_c3\", \"Current Date\").withColumnRenamed(\"_c4\", \"Next Date\")\n",
        "\n",
        "# Show DataFrame with renamed columns\n",
        "data3.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThN7b8RInsko",
        "outputId": "b1c8cef4-4582-4f0d-b27c-71c075d2008c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+------------+----------+\n",
            "|        HCHO reading|          Location|Current Date| Next Date|\n",
            "+--------------------+------------------+------------+----------+\n",
            "|                NULL|Bibile, Monaragala|  2019-01-01|2019-01-02|\n",
            "|1.919914652467399E-5|Bibile, Monaragala|  2019-01-02|2019-01-03|\n",
            "|2.811447935930283...|Bibile, Monaragala|  2019-01-03|2019-01-04|\n",
            "|3.747998184385943E-5|Bibile, Monaragala|  2019-01-04|2019-01-05|\n",
            "|-1.79826087934531...|Bibile, Monaragala|  2019-01-05|2019-01-06|\n",
            "+--------------------+------------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows\n",
        "num_rows = data1.count()\n",
        "print(\"Number of rows in data1:\", num_rows)\n",
        "num_rows = data2.count()\n",
        "print(\"Number of rows in data2:\", num_rows)\n",
        "num_rows = data3.count()\n",
        "print(\"Number of rows in data3:\", num_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3z02mqbouuk",
        "outputId": "14be8afe-ebca-4d8f-b655-1d534941fbe4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in data1: 5478\n",
            "Number of rows in data2: 1826\n",
            "Number of rows in data3: 5478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Union the three DataFrames to combine them\n",
        "full_data = data1.union(data2).union(data3)\n",
        "\n",
        "num_rows = full_data.count()\n",
        "print(\"Number of rows in full dataset:\", num_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G67DASDEpFKm",
        "outputId": "9abab99f-9d9e-48d2-b081-7b0078a49369"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in full dataset: 12782\n"
          ]
        }
      ]
    }
  ]
}